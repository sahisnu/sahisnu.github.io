<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
</head>
<body>
        <h3> 2020 </h3>
        <li>
            <b> <a href="https://www.cs.uic.edu/~liub/publications/neurips_2020_workshop_HLDS_camera_ready.pdf">
                An Application-Independent Approach to Building Task-Oriented Chatbots with Interactive Continual Learning </a>
            </b> <br/>
                Sahisnu Mazumder, Bing Liu, Shuai Wang, and Sepideh Esmaeilpour. <br/>
            <i> In NeurIPS-2020 Workshop on Human in the Loop Dialogue Systems </i> (<b> HLDS @ NeurIPS 2020 </b>)
            <br/>
            <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#mazumder2020hlds">Abstract</button>
              <div id="mazumder2020hlds" class="collapse">
                <div class="well well-sm" style="text-justify: auto;font-size: small">
                    Many real-life task-oriented chatbots are <i>natural language</i> (<i>command</i>) <i>interfaces</i>
                    (NLIs) to their underlying applications. Such a NLI is often built using a semantic parser (SP) to parse
                    the user command and convert it to a logical form, which is then translated to an executable action, or
                    using an end-to-end deep learning model. They all need large volumes of application specific data for training.
                    This paper proposes a <i>new and application independent</i> approach to building NLIs that needs no SP,
                    translator, or training. It is based on NL to NL matching, where the representations of both actions and
                    user commands are in natural language (NL). Given a user command, the system matches it with a correct action
                    representation, and executes its associated action. The system can also continuously learn new NL expressions
                    of actions from users through interactions to make the system more powerful. The learning happens during
                    chatting after the model has been deployed. Our experimental results show the effectiveness of the proposed approach.
                </div>
              </div>
            <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#mazumder2020hlds3">bib</button>
              <div id="mazumder2020hlds3" class="collapse">
                <div class="well well-sm" style="text-justify: auto;font-size: small">

                  </div>
              </div>
            <a href="#"
               class="btn btn-sm-poster" role="button" >poster</a>
        </li>
        <br/>

        <li>
            <b> <a href="https://openreview.net/pdf/333c3591213be43c8f2016391823ff6cdf5d396e.pdf">
                Continuous and Interactive Factual Knowledge Learning in Verification Dialogues </a>
            </b> <br/>
                Sahisnu Mazumder, Bing Liu, Nianzu Ma, and Shuai Wang. <br/>
            <i> In NeurIPS-2020 Workshop on Human And Machine in-the-Loop Evaluation and Learning Strategies
            </i> (<b> HAMLETS @ NeurIPS 2020 </b>)
            <br/>
            <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#mazumder2020hamlets">Abstract</button>
              <div id="mazumder2020hamlets" class="collapse">
                <div class="well well-sm" style="text-justify: auto;font-size: small">
                    Knowledge bases (KBs) used in applications such as dialogue systems need to be continuously expanded in order
                    to serve the users well. This process is known as <i>knowledge base completion</i> (KBC). A piece of
                    <i>knowledge</i> or a <i>fact</i> is often represented as a triple (\(s, r, t\)), meaning that the entity
                    \(s\) and the entity \(t\) have the relation \(r\) or are linked by \(r\). KBC builds a model to infer missing facts
                    from the existing ones in a given KB. Existing KBC research typically makes the <i>closed-world assumption</i>
                    that to infer a new fact (\(s, r, t\)), it assumes that \(s\), \(r\) and \(t\) are already in the KB, but are
                    not linked. Clearly, this assumption is a serious limitation. In this paper, we eliminate this assumption
                    and allow \(s\), \(r\) and/or \(t\) to be unknown to the KB, which we call <i>open-world knowledge base completion
                    </i> (OKBC). We focus on solving OKBC via user interactions, which enables the proposed system to potentially
                    serve as an engine for learning new knowledge during dialogue. Experimental results show the effectiveness
                    of the proposed approach.
                </div>
              </div>
            <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#mazumder2020hamlets3">bib</button>
              <div id="mazumder2020hamlets3" class="collapse">
                <div class="well well-sm" style="text-justify: auto;font-size: small">

                  </div>
              </div>
            <a href="#"
               class="btn btn-sm-poster" role="button" >poster</a>
        </li>
        <br/>

        <li>
            <b> <a href="https://www.aclweb.org/anthology/2020.coling-main.50.pdf">
                Bayes-enhanced Lifelong Attention Networks for Sentiment Classification </a>
            </b> <br/>
                Hao Wang, Shuai Wang, Sahisnu Mazumder, Bing Liu, Yan Yang, and Tianrui Li. <br/>
            <i> In Proceedings of International Conference on Computational Linguistics </i> (<b> COLING 2020 </b>)
            <br/>
            <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#hao2020coling">Abstract</button>
              <div id="hao2020coling" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
            <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#hao2020coling3">bib</button>
              <div id="hao2020coling3" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
        </li>
        <br/>

        <li>
            <b> <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.146.pdf">
                A Knowledge-Driven Approach to Classifying Object and Attribute Coreferences in Opinion Mining </a>
            </b> <br/>
                Jiahua Chen, Shuai Wang, Sahisnu Mazumder, and Bing Liu. <br/>
            <i> In Findings of ACL : Conference on Empirical Methods in Natural Language Processing
            </i> (<b> EMNLP 2020, Findings </b>)
            <br/>
            <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#chen2020emnlp">Abstract</button>
              <div id="chen2020emnlp" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
            <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#chen2020emnlp3">bib</button>
              <div id="chen2020emnlp3" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
        </li>
        <br/>

        <li>
            <b> <a href="https://www.aclweb.org/anthology/2020.acl-main.512.pdf">
                Entity-Aware Dependency-Based Deep Graph Attention Network for Comparative Preference Classification </a>
            </b> <br/>
                Nianzu Ma, Sahisnu Mazumder, Hao Wang, and Bing Liu. <br/>
            <i> In Proceedings of Annual Meeting of the Association for Computational Linguistics </i> (<b> ACL 2020 </b>)
            <br/>
            <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#ma2020acl">Abstract</button>
              <div id="ma2020acl" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
            <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#ma2020acl3">bib</button>
              <div id="ma2020acl3" class="collapse">
                <div class="well well-sm">Small Well</div>
              </div>
        </li>
        <br/>

</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
</head>
<body>
    <h3> 2022 </h3>
    <li>
        <b> <a href="https://aclanthology.org/2022.emnlp-main.627.pdf">
            Semantic Novelty Detection and Characterization in Factual Text Involving Named Entities </a>
        </b> <br/>
        Nianzu Ma, Sahisnu Mazumder, Alexander Politowicz, Bing Liu, Eric Robertson, Scott Grigsby. <br/>
        <i> In Proceedings of Conference on Empirical Methods in Natural Language Processing </i> (<b> EMNLP 2022 </b>)
        <br/>
        <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#liu2022self">Abstract</button>
        <div id="liu2022self" class="collapse">
            <div class="well well-sm" style="text-justify: auto;font-size: small">
                Much of the existing work on text novelty detection has been studied at the topic level, i.e., identifying
                whether the topic
                of a document or a sentence is novel or not. Little work has been done at the fine-grained semantic level
                (or contextual level).
                For example, given that we know Elon Musk is the CEO of a technology company, the sentence "Elon Musk acted
                in the sitcom The Big Bang Theory"
                is novel and surprising because normally a CEO would not be an actor. Existing topic-based novelty detection
                methods work poorly on
                this problem because they do not perform semantic reasoning involving relations between named entities in
                the text and their
                background knowledge. This paper proposes an effective model (called PAT-SND) to solve the problem, which
                can also characterize the novelty.
                An annotated dataset is also created. Evaluation shows that PAT-SND outperforms 10 baselines by large
                margins.
            </div>
        </div>
        <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#liu2021self3">bib</button>
        <div id="liu2022self3" class="collapse">
            <div class="well well-sm">Small Well</div>
        </div>
        <a href="#"
           class="btn btn-sm-sld" role="button">slides</a>
    </li>
    <br/>

    <li>
    <b> <a href="https://arxiv.org/pdf/2210.15670.pdf">
        Knowledge-Guided Exploration in Deep Reinforcement Learning </a>
    </b> <br/>
    Sahisnu Mazumder, Bing Liu, Shuai Wang, Yingxuan Zhu, Xiaotian Yin, Lifeng Liu, Jian Li <br/>
    <i> arXiv preprint arXiv:2210.15670 </i>
    <br/>
    <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#liu2022self">Abstract</button>
    <div id="liu2022self" class="collapse">
        <div class="well well-sm" style="text-justify: auto;font-size: small">
            This paper proposes a new method to drastically speed up deep reinforcement learning (deep RL) training for
            problems
            that have the property of state-action permissibility (SAP). Two types of permissibility are defined under
            SAP. The first
            type says that after an action is performed in a state and the agent has reached the new state , the agent
            can decide whether
            is permissible or not permissible in . The second type says that even without performing in , the agent can
            already decide whether
            is permissible or not in . An action is not permissible in a state if the action can never lead to an
            optimal solution and thus
            should not be tried (over and over again). We incorporate the proposed SAP property and encode action
            permissibility knowledge
            into two state-of-the-art deep RL algorithms to guide their state-action exploration together with a virtual
            stopping strategy.
            Results show that the SAP-based guidance can markedly speed up RL training.
        </div>
    </div>
    <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#liu2021self3">bib</button>
    <div id="liu2022self3" class="collapse">
        <div class="well well-sm">Small Well</div>
    </div>
    <a href="#"
       class="btn btn-sm-sld" role="button">slides</a>
    </li>
    <br/>

    <li>
    <b> <a href="https://arxiv.org/pdf/2110.11385.pdf">
        Self-Initiated Open World Learning for Autonomous AI Agents </a>
    </b> <br/>
    Bing Liu, Eric Robertson, Scott Grigsby, Sahisnu Mazumder. <br/>
    <i> In the Spring Symposium of the Association for the Advancement of Artificial Intelligence </i> (<b> AAAI Spring
    Symposium 2022</b> )
    <br/>
    <button type="button" class="btn btn-sm-abs" data-toggle="collapse" data-target="#liu2021self">Abstract</button>
    <div id="liu2021self" class="collapse">
        <div class="well well-sm" style="text-justify: auto;font-size: small">
            As more and more AI agents are used in practice, it is time to think about how to make these agents
            fully autonomous so that they can learn by themselves in a self-motivated and self-supervised manner
            rather than being retrained periodically on the initiation of human engineers using expanded training
            data. As the real-world is an open environment with unknowns or novelties, detecting novelties or unknowns,
            gathering ground-truth training data, and incrementally learning the unknowns make the agent more and more
            knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried
            out on the agent's own initiative and through its own interactions with humans and the environment. Since an
            AI agent usually has a performance task, characterizing each novelty becomes necessary so that the agent can
            formulate an appropriate response to adapt its behavior to cope with the novelty and to learn from it to
            improve its future responses and task performance. This paper proposes a theoretic framework for this
            learning
            paradigm to promote the research of building self-initiated open world learning agents.
        </div>
    </div>
    <button type="button" class="btn btn-sm-bib" data-toggle="collapse" data-target="#liu2021self3">bib</button>
    <div id="liu2021self3" class="collapse">
        <div class="well well-sm">Small Well</div>
    </div>
    <a href="#"
       class="btn btn-sm-sld" role="button">slides</a>
    </li>
    <br/>
</body>
</html>